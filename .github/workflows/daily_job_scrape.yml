name: Daily LinkedIn Job Scrape

on:
  schedule:
    # Runs every day at 08:00 UTC (adjust as needed)
    - cron: '0 8 * * *'
  workflow_dispatch: # Allows manual triggering
    inputs:
      mode:
        description: 'Scraping mode to run'
        required: true
        default: 'default'
        type: choice
        options:
          - default
          - deep

jobs:
  scrape_jobs:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11' # Or your preferred Python version

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Create Google Credentials file
        env:
          GOOGLE_CREDENTIALS_CONTENT: ${{ secrets.GOOGLE_CREDENTIALS_JSON }}
        run: |
          echo "Creating credentials.json..."
          echo "$GOOGLE_CREDENTIALS_CONTENT" > credentials.json
          echo "credentials.json created."
          # Verify file content for debugging (optional, remove in production if sensitive)
          # echo "credentials.json content:"
          # cat credentials.json 

      - name: Determine script mode
        id: script_mode
        run: |
          if [[ "${{ github.event_name }}" == "schedule" ]]; then
            echo "Running in scheduled mode: default"
            echo "mode=default" >> $GITHUB_OUTPUT
          else
            echo "Running in manual mode: ${{ github.event.inputs.mode }}"
            echo "mode=${{ github.event.inputs.mode }}" >> $GITHUB_OUTPUT
          fi

      - name: Run job scraper
        # GOOGLE_SHEET_ID is hardcoded in config.py
        # GOOGLE_CREDENTIALS_PATH is already set to credentials.json in config.py by default
        run: |
          echo "Starting job scrape in ${{ steps.script_mode.outputs.mode }} mode..."
          python main.py --mode ${{ steps.script_mode.outputs.mode }}
          echo "Job scrape finished."

      - name: Clean up credentials file
        if: always() # Ensures this step runs even if previous steps fail
        run: |
          echo "Cleaning up credentials.json..."
          rm -f credentials.json
          echo "credentials.json removed." 